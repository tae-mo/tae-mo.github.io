
<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="description"
    content="Nuvo: Neural UV Mapping">
  <meta name="keywords" content="NeRF">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Grid-Based Continuous Normal Representation for Anomaly Detection</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
  <script src="./static/js/video_comparison.js"></script>
  <link rel="icon"
    href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üèÅ</text></svg>">
</head>

<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">

            <h1 class="title is-1 publication-title">Grid-Based Continuous Normal Representation for Anomaly Detection</h1>
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="https://maincold2.github.io">Joo Chan Lee*</a>,</span>
              <span class="author-block">
                <a href="https://maincold2.github.io">Taejune Kim*</a>,</span>
              <span class="author-block">
                <a href="https://silverbottlep.github.io/">Eunbyung Park</a>,</span>
              <span class="author-block">
                <a href="https://dash-lab.github.io/">Simon S. Woo</a>,</span>
              <span class="author-block">
                <a href="https://iris.skku.edu/">Jong Hwan Ko</a></span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block">Sungkyunkwan University</span>
            </div>

            <div class="is-size-5 publication-venue">

            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- PDF Link. -->
                <!-- <span class="link-block">
                  <a href="" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Paper</span>
                  </a>
                </span> -->
                <span class="link-block">
                  <a href="http://arxiv.org/abs/2312.05283" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>arXiv</span>
                  </a>
                </span>
                <!-- <span class="link-block">
                  <a class="external-link button is-normal is-rounded is-dark" title="Coming soon!" disabled>
                    <span class="icon">
                        <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                    </a>
                </span>
                <span class="link-block">
                  <a class="external-link button is-normal is-rounded is-dark" title="Coming soon!" disabled>
                    <span class="icon">
                        <i class="far fa-images"></i>
                    </span>
                    <span>Data</span>
                    </a>
                  </span> -->

              </div>

            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="hero teaser">
    <div class="container is-max-desktop">
      <div class="hero-body">
        <div class="tabs-widget">
          <div class="tabs is-centered is-toggle is-toggle-rounded">
            <ul class="is-marginless">
              <li class="is-active"><a>GRAD</a></li>
              <li><a>xatlas</a></li>
            </ul>
          </div>
          <div class="tabs-content">
            <div>
              <video id="replay-video" controls muted preload playsinline autoplay loop width="70%">
                <source src="./static/videos/gardenvase_ours.mp4" type="video/mp4">
              </video>
              <img width="25%" src="./static/images/gardenvase_normals.png"></img>
            </div>
            <div>
              <video id="replay-video" controls muted preload playsinline autoplay loop width="70%">
                <source src="./static/videos/gardenvase_cb_xatlas.mp4" type="video/mp4">
              </video>
              <img width="25%" src="./static/images/xatlas_normals.png"></img>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <hr />

  <section class="section">
    <div class="container is-max-desktop">
      <!-- Abstract. -->
      <h2 class="title is-3">Abstract</h2>
      <div class="content has-text-justified">
        <p>
            There have been significant advancements in anomaly detection in an unsupervised manner, where only normal images are available for training. Several recent methods aim to detect anomalies based on a memory, comparing the input and the directly stored normal features (or trained features with normal images).
            However, such memory-based approaches operate on a discrete feature space implemented by the nearest neighbor or attention mechanism, suffering from poor generalization or an identity shortcut issue outputting the same as input, respectively.
            Furthermore, the majority of existing methods are designed to detect single-class anomalies, resulting in unsatisfactory performance when presented with multiple classes of objects.
            To tackle all of the above challenges, we propose GRAD, a novel anomaly detection method for representing normal features within a "continuous" feature space, enabled by transforming spatial features into coordinates and mapping them to continuous grids. 
            Furthermore, we carefully design the grids tailored for anomaly detection, representing both local and global normal features and fusing them effectively.
            Our extensive experiments demonstrate that GRAD successfully generalizes the normal features and mitigates the identity shortcut, furthermore, GRAD effectively handles diverse classes in a single model thanks to the high-granularity global representation.
            In an evaluation using the MVTec AD dataset, GRAD significantly outperforms the previous state-of-the-art method by reducing 65.0\% of the error for multi-class unified anomaly detection.
        </p>
      </div>
      <img width="100%" src="./static/images/method.png"></img>
      <p>
        Nuvo uses a neural field to represent a given scene's UV mapping.
        A "chart assignment" MLP c outputs probabilities for a categorical distribution over charts for any surface point x,
        "texture coordinate" MLPs t map from 3D points x to 2D UV coordinates u, and ``surface coordinate'' MLPs s map from 2D UV coordinates to 3D points on the surface.
        Here we visualize Nuvo's learned mappings for charts 1 and 3 in an atlas consisting of 4 charts.
      </p>
      <!-- / Abstract. -->

    </div>

    </div>
  </section>

  <hr/>

  <section class="section">
    <div class="container is-max-desktop">
      <!-- Video. -->
      <h2 class="title is-3">Video</h2>
      <!-- Paper video. -->
      <div class="container is-max-desktop">
        <!-- <h2 class="title is-3">Video</h2> -->
        <div class="publication-video">
          <iframe src="https://www.youtube.com/embed/hmJiOSTDQZI?si=Xq4TWH4D9BwMmlp7"
                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
        </div>
      </div>
    </div>
      <!--/ Paper video. -->
    </div>
  </section>

  <hr/>

  <section class="section">
    <div class="container is-max-desktop">

      <h2 class="title is-3">Optimization Convergence</h2>

      <div class="content has-text-justified">
        <p>
          Nuvo parameterizes a UV mapping as a neural field that is optimized to partition the scene into a set of charts, each representing a low-distortion mapping from a region of the scene onto a 2D square.
          Here we're visualizing Nuvo's optimization convergence for computing UV mappings for the "Bust of Queen Nefertiti" mesh using 4, 8, or 16 charts.
        </p>
      </div>

      <div class="content">
        <div class="tabs-widget">
          <div class="tabs is-centered">
            <ul class="is-marginless">
              <li class="is-active"><a>4 charts</a></li>
              <li><a>8 charts</a></li>
              <li><a>16 charts</a></li>
            </ul>
          </div>
          <div class="tabs-content">
            <div>
              <video id="replay-video" controls muted preload playsinline autoplay loop width="100%">
                <source src="./static/videos/nefertiti_4_opt_comb_pad.mp4" type="video/mp4">
              </video>
            </div>

            <div>
              <video id="replay-video" controls muted preload playsinline autoplay loop width="100%">
                <source src="./static/videos/nefertiti_8_opt_comb_pad.mp4" type="video/mp4">
              </video>
            </div>

            <div>
              <video id="replay-video" controls muted preload playsinline autoplay loop width="100%">
                <source src="./static/videos/nefertiti_16_opt_comb.mp4" type="video/mp4">
              </video>
            </div>

          </div>
        </div>

      </div>

    </div>
  </section>

  <hr/>

  <section class="section">
    <div class="container is-max-desktop">
      <h2 class="title is-3">Appearance Editing</h2>

      <div class="content has-text-justified">
        <p>
          Nuvo's UV mappings enable us to use off-the-shelf 2D image editing tools to edit the appearance of generated and 3D reconstructed content.
          Here, we're modifying mesh albedos in UV space using Adobe Firefly's generative inpainting.
        </p>
      </div>
      <h5 class="title is-5">DreamFusion mesh: "A ghost eating a hamburger"</h5>
      <video id="replay-video" controls muted preload playsinline autoplay loop width="100%">
        <source src="./static/videos/ghost_edit_comb_flip.mp4" type="video/mp4">
      </video>
      <div class="columns is-mobile has-text-centered is-size-7-mobile">
        <div class="column is-one-half">Original</div>
        <div class="column is-one-half">Edited</div>
      </div>
      <h5 class="title is-5">Zip-NeRF mesh: gardenvase</h5>
      <video id="replay-video" controls muted preload playsinline autoplay loop width="100%">
        <source src="./static/videos/gardenvase_edit_comb.mp4" type="video/mp4">
      </video>
      <div class="columns is-mobile has-text-centered is-size-7-mobile">
        <div class="column is-one-half">Original</div>
        <div class="column is-one-half">Edited</div>
      </div>
      <h5 class="title is-5">Zip-NeRF mesh: basil</h4>
      <video id="replay-video" controls muted preload playsinline autoplay loop width="100%">
        <source src="./static/videos/basil_edit_comb.mp4" type="video/mp4">
      </video>
      <div class="columns is-mobile has-text-centered is-size-7-mobile">
        <div class="column is-one-half">Original</div>
        <div class="column is-one-half">Edited</div>
      </div>
    </div>
  </section>

  <hr/>

  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">Acknowledgements</h2>
      <p>
        Thanks to <a href="http://szeliski.org/">Rick Szeliski</a> and <a href="https://phogzone.com/">Peter Hedman</a>
        for feedback and comments.
      </p>
      <p>
        The "Bust of Queen Nefertiti" mesh shown above was downloaded from <a href="https://github.com/alecjacobson/common-3d-test-models">Alec Jacobson's collection of 3D models</a>, and was created from a 3D scan of Thutmose's statue, located in the Neues Museum in Berlin.
          The "Hydria Apothecary Vase" mesh seen in our video (downloaded from <a href="https://sketchfab.com/3d-models/hydria-apothecary-vase-7d6938c0c0b54b06a0210a982a73023e">Sketchfab</a>) is from the
            Pharmacy Museum in the Jagiellonian University Medical College of Krak√≥w, Poland, digitized by the Regional Digitalisation Lab of the
            Malopolska Institute of Culture.
      </p>
    </div>
  </section>

  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@article{srinivasan2023nuvo,
  author    = {Pratul P. Srinivasan and Stephan J. Garbin and Dor Verbin and Jonathan T. Barron and Ben Mildenhall},
  title     = {Nuvo: Neural UV Mapping for Unruly 3D Representations},
  journal = {arXiv},
  year      = {2023},
}</code></pre>
    </div>
  </section>


  <footer class="footer">
    <div class="container">
      <div class="content has-text-centered">
        <a class="icon-link" href="http://arxiv.org/abs/2312.05283">
          <i class="fas fa-file-pdf"></i>
        </a>
        <!-- <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
          <i class="fab fa-github"></i>
        </a> -->
      </div>
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">
            <p>
              This website design comes from <a href="https://keunhong.com/">Keunhong Park's</a> <a href="https://camp-nerf.github.io/">CamP project page</a>.
            </p>
          </div>
        </div>
      </div>
    </div>
  </footer>

</body>

</html>
